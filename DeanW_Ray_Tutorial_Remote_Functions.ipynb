{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeanW - Ray Tutorial - Remote Functions",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "382.391px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deanwampler/RISECamp2019Tutorials/blob/master/DeanW_Ray_Tutorial_Remote_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-thKr9rm_2rB"
      },
      "source": [
        "# Install Dependencies\n",
        "\n",
        "If you are running on Google Colab, you need to install the necessary dependencies before beginning the exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zCb7eB-l_-HH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "5f67d3b7-4971-4e16-8ad5-9ef6f4a337f3"
      },
      "source": [
        "print('NOTE: Intentionally crashing session to use the newly installed library.\\n')\n",
        "\n",
        "!pip uninstall -y pyarrow\n",
        "!pip install ray[debug]==0.7.5\n",
        "!pip install bs4\n",
        "\n",
        "# A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "import os\n",
        "os._exit(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOTE: Intentionally crashing session to use the newly installed library.\n",
            "\n",
            "Uninstalling pyarrow-0.14.1:\n",
            "  Successfully uninstalled pyarrow-0.14.1\n",
            "Collecting ray[debug]==0.7.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/e7/37a7f8dc2b1f96c760a3950d8bb5a3f14066f1699f5d004f0f6462d880c9/ray-0.7.5-cp36-cp36m-manylinux1_x86_64.whl (74.9MB)\n",
            "\u001b[K     |████████████████████████████████| 74.9MB 69.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray[debug]==0.7.5) (7.0)\n",
            "Collecting redis>=3.3.2 (from ray[debug]==0.7.5)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ae/28613a62eea0d53d3db3147f8715f90da07667e99baeedf1010eb400f8c0/redis-3.3.11-py2.py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 17.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from ray[debug]==0.7.5) (1.16.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[debug]==0.7.5) (3.13)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[debug]==0.7.5) (2.6.0)\n",
            "Collecting funcsigs (from ray[debug]==0.7.5)\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray[debug]==0.7.5) (3.6.4)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[debug]==0.7.5) (1.12.0)\n",
            "Collecting protobuf>=3.8.0 (from ray[debug]==0.7.5)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/52/d8d2dbff74b8bf517c42db8d44c3f9ef6555e6f5d6caddfa3f207b9143df/protobuf-3.10.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[debug]==0.7.5) (3.0.12)\n",
            "Collecting colorama (from ray[debug]==0.7.5)\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
            "Collecting setproctitle; extra == \"debug\" (from ray[debug]==0.7.5)\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/0d/dc0d2234aacba6cf1a729964383e3452c52096dc695581248b548786f2b3/setproctitle-1.1.10.tar.gz\n",
            "Requirement already satisfied: psutil; extra == \"debug\" in /usr/local/lib/python3.6/dist-packages (from ray[debug]==0.7.5) (5.4.8)\n",
            "Collecting py-spy; extra == \"debug\" (from ray[debug]==0.7.5)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/49/7cea4c6ddcec7bf944c0508f480a25c9c309c6e5b96039e3aff33a579509/py_spy-0.2.2-py2.py3-none-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 28.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]==0.7.5) (19.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]==0.7.5) (7.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]==0.7.5) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]==0.7.5) (41.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]==0.7.5) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]==0.7.5) (1.8.0)\n",
            "Building wheels for collected packages: setproctitle\n",
            "  Building wheel for setproctitle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for setproctitle: filename=setproctitle-1.1.10-cp36-cp36m-linux_x86_64.whl size=33928 sha256=f2cf308275a7ba85317c8e561439f42c65f386c637bcea86b44e5852e8b87d68\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/b1/a6/9719530228e258eba904501fef99d5d85c80d52bd8f14438a3\n",
            "Successfully built setproctitle\n",
            "Installing collected packages: redis, funcsigs, protobuf, colorama, setproctitle, py-spy, ray\n",
            "  Found existing installation: protobuf 3.7.1\n",
            "    Uninstalling protobuf-3.7.1:\n",
            "      Successfully uninstalled protobuf-3.7.1\n",
            "Successfully installed colorama-0.4.1 funcsigs-1.0.2 protobuf-3.10.0 py-spy-0.2.2 ray-0.7.5 redis-3.3.11 setproctitle-1.1.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l6wpgwlHdfus"
      },
      "source": [
        "# Exercise 1 - Simple Parallelization\n",
        "\n",
        "**GOAL:** The goal of this exercise is to show how to run simple tasks in parallel.\n",
        "\n",
        "This script is running too slowly, but the computation is embarrassingly parallel. In this exercise, you will use Ray to execute the functions in parallel to speed it up.\n",
        "\n",
        "### Introduction to Remote Functions\n",
        "\n",
        "The `@ray.remote` decorator turns a Python function into a \"remote function\" that Ray can run in parallel. Here is a simple example:\n",
        "\n",
        "```python\n",
        "# A regular Python function.\n",
        "def regular_function():\n",
        "    return 1\n",
        "\n",
        "# A Ray remote function.\n",
        "@ray.remote\n",
        "def remote_function():\n",
        "    return 1\n",
        "```\n",
        "\n",
        "There are a few key differences between the original function and the decorated one:\n",
        "\n",
        "1. **Invocation:** The regular version is called with `regular_function()`, whereas the remote version is called with `remote_function.remote()`.\n",
        "2. **Return values:** `regular_function` executes synchronously and returns the result of the function (`1`), whereas `remote_function` immediately returns an `ObjectID` (a future) and then executes the task in the background on a separate worker process. The result of the future can be obtained by calling `ray.get` on the `ObjectID`.\n",
        "    ```python\n",
        "    >>> regular_function()\n",
        "    1\n",
        "    \n",
        "    >>> remote_function.remote()\n",
        "    ObjectID(1c80d6937802cd7786ad25e50caf2f023c95e350)\n",
        "    \n",
        "    >>> ray.get(remote_function.remote())\n",
        "    1\n",
        "    ```\n",
        "3. **Parallelism:** Invocations of `regular_function` happen **serially**:\n",
        "    ```python\n",
        "    # These are executed one at a time, back-to-back.\n",
        "    result = 0\n",
        "    for _ in range(4):\n",
        "        result += regular_function()\n",
        "    assert result == 4\n",
        "    ```\n",
        "    In contrast, invocations of `remote_function` happen in **parallel**:\n",
        "    ```python\n",
        "    # Executing these functions happens at the same time in the background, and we get the results using ray.get.\n",
        "    results = []\n",
        "    for _ in range(4):\n",
        "        results.append(remote_function.remote())\n",
        "    assert sum(ray.get(results)) == 4\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xLJx-XpJdfuu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f7190a5-2561-4afe-a7ab-8c0b48443131"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import ray\n",
        "import time\n",
        "\n",
        "print('Successfully imported ray!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully imported ray!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PvwwpldHdfux"
      },
      "source": [
        "Start the processes that make up the Ray runtime. By default, Ray does not schedule more tasks concurrently than there are CPUs, but this example requires four tasks to run concurrently, so we tell Ray that there are four CPUs. In practice, you would usually just let Ray detect the number of CPUs on the machine.\n",
        "\n",
        "`ignore_reinit_error=True` just suppresses errors if the cell is run multiple times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MjLO5L4dfux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4113a220-48ce-4ed6-fe5b-fba85f6bd66e"
      },
      "source": [
        "ray.init(num_cpus=4, ignore_reinit_error=True)\n",
        "\n",
        "# Sleep a little to improve the accuracy of the timing measurements used below,\n",
        "# because some workers may still be starting up in the background.\n",
        "time.sleep(2.0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-17 15:48:53,730\tINFO resource_spec.py:205 -- Starting Ray with 6.3 GiB memory available for workers and up to 3.17 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D35JdJQ8dfu1"
      },
      "source": [
        "**EXERCISE:** The loop below takes too long, but the four function calls could be executed in parallel. This should speed up the execution from four seconds to one second. \n",
        "\n",
        "First, turn `slow_function` into a remote function, then execute the tasks in parallel by calling `slow_function.remote()` and obtaining the results with `ray.get` on the list of returned object IDs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pnNgl3cddfu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "678606fa-acf5-4ddd-ad21-60f0e2e629f8"
      },
      "source": [
        "# A function simulating a more interesting computation that takes one second.\n",
        "@ray.remote\n",
        "def slow_function(i):\n",
        "    time.sleep(1)\n",
        "    return i\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "results1 = []\n",
        "for i in range(4):\n",
        "  results1.append(slow_function.remote(i))\n",
        "results = ray.get(results1) \n",
        "\n",
        "duration = time.time() - start_time\n",
        "print('Executing the for loop took {:.3f} seconds.'.format(duration))\n",
        "print('The results are:', results)\n",
        "print('Run the next cell to check if the exercise was performed correctly.')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing the for loop took 1.015 seconds.\n",
            "The results are: [0, 1, 2, 3]\n",
            "Run the next cell to check if the exercise was performed correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r_FfKxocdfu3"
      },
      "source": [
        "**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IlrIrAyldfu4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "993af998-6081-4273-987d-b67e23e29f21"
      },
      "source": [
        "assert results == [0, 1, 2, 3], 'Did you remember to call ray.get?'\n",
        "assert duration < 1.1, ('The loop took {:.3f} seconds. This is too slow.'\n",
        "                        .format(duration))\n",
        "assert duration > 1, ('The loop took {:.3f} seconds. This is too fast.'\n",
        "                      .format(duration))\n",
        "\n",
        "print('Success! The example took {} seconds.'.format(duration))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! The example took 1.014702558517456 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AC1rwahidfu5"
      },
      "source": [
        "**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n",
        "\n",
        "1. Run the following cell to generate a JSON file containing the profiling data.\n",
        "2. Download the timeline file by right clicking on `exercise_1.json` in the **Files** tab in the navigator to the left, right clicking, and selecting  **\"Download\"**.\n",
        "3. Enter **chrome://tracing** into the Chrome web browser, click on the **\"Load\"** button, and select the downloaded JSON file.\n",
        "\n",
        "To navigate within the timeline:\n",
        "- Move around by clicking and dragging.\n",
        "- Zoom in and out by holding **alt** on Windows or **option** on Mac and scrolling.\n",
        "\n",
        "**NOTE:** The timeline visualization will only work in **Chrome**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LmYOA4sGdfu6",
        "colab": {}
      },
      "source": [
        "ray.timeline(filename=\"exercise_1.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TD9T8jPYd2bO"
      },
      "source": [
        "# Exercise 2 - Parallel Data Processing with Task Dependencies\n",
        "\n",
        "**GOAL:** The goal of this exercise is to pass object IDs into remote functions to encode dependencies between tasks.\n",
        "\n",
        "In this exercise, we construct a sequence of tasks, each of which depends on the previous, mimicking a data parallel application. Within each sequence, tasks are executed serially, but multiple sequences of tasks can be executed in parallel. You will use Ray to speed up the computation by parallelizing the sequences.\n",
        "\n",
        "### Concept for this Exercise - Task Dependencies\n",
        "\n",
        "Consider the following basic remote function that returns the argument passed to it. If we pass in some normal Python objects, the results returned by `ray.get` should be the same objects.\n",
        "\n",
        "```python\n",
        "@ray.remote\n",
        "def f(x):\n",
        "    return x\n",
        "\n",
        ">>> x1_id = f.remote(1)\n",
        ">>> ray.get(x1_id)\n",
        "1\n",
        "\n",
        ">>> x2_id = f.remote([1, 2, 3])\n",
        ">>> ray.get(x2_id)\n",
        "[1, 2, 3]\n",
        "```\n",
        "\n",
        "However, **object IDs** can also be passed into remote functions. When the function is executed, Ray will automatically substitute the underlying Python object that the object ID refers to. In a sense, it's the same as calling `ray.get` on each argument that's passed in as an argument.\n",
        "\n",
        "```python\n",
        ">>> y1_id = f.remote(x1_id)\n",
        ">>> ray.get(y1_id)\n",
        "1\n",
        "\n",
        ">>> y2_id = f.remote(x2_id)\n",
        ">>> ray.get(y2_id)\n",
        "[1, 2, 3]\n",
        "```\n",
        "\n",
        "When implementing a remote function, the function should expect a regular Python object regardless of whether the caller passes in a regular Python object or an object ID.\n",
        "\n",
        "**These task dependencies affect scheduling.** In the example above, the task that creates `y1_id` depends on the task that creates `x1_id`. This means that:\n",
        "\n",
        "- The second task will not be executed until the first task has finished executing.\n",
        "- If the two tasks are scheduled on different machines, the output of the first task (the value corresponding to `x1_id`) will be copied over the network to the machine where the second task is scheduled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jRayjahDd-AU",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import ray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "csUGAU13d-Zs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "176cf465-33c3-4180-90b7-9e914fd481f7"
      },
      "source": [
        "ray.init(num_cpus=4, ignore_reinit_error=True)\n",
        "\n",
        "# Sleep a little to improve the accuracy of the timing measurements used below,\n",
        "# because some workers may still be starting up in the background.\n",
        "time.sleep(2.0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-17 16:20:16,279\tERROR worker.py:1432 -- Calling ray.init() again after it has already been called.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dGrF31cceDMk"
      },
      "source": [
        "**EXERCISE:** Below are some helper functions that mimic the pattern of a data parallel application that we want to speed up. To do so, you'll need to turn all of these functions into remote functions. Remember that you don't need to worry about whether the caller passes in an object ID or a regular object, because in both cases the arguments will be regular objects when the function executes. This means that even if you pass in an object ID, you **do not need to call `ray.get`** inside of these remote functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZU1nRG8beACP",
        "colab": {}
      },
      "source": [
        "@ray.remote\n",
        "def load_data(filename):\n",
        "    time.sleep(0.1)\n",
        "    return np.ones((1000, 100))\n",
        "\n",
        "@ray.remote\n",
        "def normalize_data(data):\n",
        "    time.sleep(0.1)\n",
        "    return data - np.mean(data, axis=0)\n",
        "\n",
        "@ray.remote\n",
        "def extract_features(normalized_data):\n",
        "    time.sleep(0.1)\n",
        "    return np.hstack([normalized_data, normalized_data ** 2])\n",
        "\n",
        "@ray.remote\n",
        "def compute_loss(features):\n",
        "    num_data, dim = features.shape\n",
        "    time.sleep(0.1)\n",
        "    return np.sum((np.dot(features, np.ones(dim)) - np.ones(num_data)) ** 2)\n",
        "\n",
        "assert hasattr(load_data, 'remote'), 'load_data must be a remote function'\n",
        "assert hasattr(normalize_data, 'remote'), 'normalize_data must be a remote function'\n",
        "assert hasattr(extract_features, 'remote'), 'extract_features must be a remote function'\n",
        "assert hasattr(compute_loss, 'remote'), 'compute_loss must be a remote function'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TlF-_kc2eHc4"
      },
      "source": [
        "**EXERCISE:** The loop below takes too long. Parallelize the four passes through the loop by turning `load_data`, `normalize_data`, `extract_features`, and `compute_loss` into remote functions and then retrieving the losses with `ray.get`.\n",
        "\n",
        "**NOTE:** You should only use **ONE** call to `ray.get`. For example, the object ID returned by `load_data` should be passed directly into `normalize_data` without needing to be retrieved by the driver."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rX-brDlaeFNZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c8472342-2e2e-4275-9849-af4c822aea6c"
      },
      "source": [
        "start_time = time.time()\n",
        "losses = []\n",
        "for filename in ['file1', 'file2', 'file3', 'file4']:\n",
        "    inner_start = time.time()\n",
        "\n",
        "    data = load_data.remote(filename)\n",
        "    normalized_data = normalize_data.remote(data)\n",
        "    features = extract_features.remote(normalized_data)\n",
        "    loss = compute_loss.remote(features)\n",
        "    losses.append(loss)\n",
        "    \n",
        "    inner_end = time.time()\n",
        "    \n",
        "    if inner_end - inner_start >= 0.1:\n",
        "        raise Exception('You may be calling ray.get inside of the for loop! '\n",
        "                        'Doing this will prevent parallelism from being exposed. '\n",
        "                        'Make sure to only call ray.get once outside of the for loop.')\n",
        "\n",
        "print('The losses are {}.'.format(losses) + '\\n')\n",
        "loss = sum(ray.get(losses))\n",
        "\n",
        "duration = time.time() - start_time\n",
        "\n",
        "print('The loss is {}. This took {:.3f} seconds. Run the next cell to see '\n",
        "      'if the exercise was done correctly.'.format(loss, duration))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The losses are [ObjectID(ea33e127ed2dffffffff0100000000c001000000), ObjectID(ce2291bff681ffffffff0100000000c001000000), ObjectID(5f7bdf6afbe0ffffffff0100000000c001000000), ObjectID(383a92d6719effffffff0100000000c001000000)].\n",
            "\n",
            "The loss is 4000.0. This took 0.466 seconds. Run the next cell to see if the exercise was done correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nOevdR4LeLlk"
      },
      "source": [
        "**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FlTAyw09eJSL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1be8ebd1-8deb-4e2e-9906-dd8bb0a627f7"
      },
      "source": [
        "assert loss == 4000\n",
        "assert duration < 0.8, ('The loop took {:.3f} seconds. This is too slow.'\n",
        "                        .format(duration))\n",
        "assert duration > 0.4, ('The loop took {:.3f} seconds. This is too fast.'\n",
        "                        .format(duration))\n",
        "\n",
        "print('Success! The example took {:.3f} seconds.'.format(duration))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! The example took 0.466 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r1fHJZWDeRGb"
      },
      "source": [
        "**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n",
        "\n",
        "1. Run the following cell to generate a JSON file containing the profiling data.\n",
        "2. Download the timeline file by right clicking on `exercise_2.json` in the **Files** tab in the navigator to the left, right clicking, and selecting  **\"Download\"**.\n",
        "3. Enter **chrome://tracing** into the Chrome web browser, click on the **\"Load\"** button, and select the downloaded JSON file.\n",
        "\n",
        "To navigate within the timeline:\n",
        "- Move around by clicking and dragging.\n",
        "- Zoom in and out by holding **alt** on Windows or **option** on Mac and scrolling.\n",
        "\n",
        "**NOTE:** The timeline visualization will only work in **Chrome**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R96y_U99eRdg",
        "colab": {}
      },
      "source": [
        "ray.timeline(filename=\"exercise_2.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4UMNWDWOeVI2"
      },
      "source": [
        "### Application: Parallel web-scraping\n",
        "\n",
        "One useful application of what we have learned so far is to scrape information from the web. We will illustrate this in a toy setting, but the same principles apply on a large scale where crawling through websites, parsing them and extracting useful content (e.g. for building a search index or populating a database) is often very computationally demanding.\n",
        "\n",
        "We break up the process into multiple steps. We first grab the raw HTML of the website using Python's requests package. Then, we use BeautifulSoup to parse the HTML to find the relevant information. Finally, we populate a pandas DataFrames so that we are able to work with the data.\n",
        "\n",
        "To demonstrate this, we scrape GitHub commits to see the latest commits on several repositories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6apTGnCZeTDA",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IYW3fS-Aeg2s"
      },
      "source": [
        "The following function uses these libraries to parse the latest commits from several repositories on GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GXRdG9zYehhI",
        "colab": {}
      },
      "source": [
        "@ray.remote\n",
        "def fetch_commits(repo):\n",
        "    url = 'https://github.com/{}/commits/master'.format(repo)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'lxml')\n",
        "    df = pd.DataFrame(columns=['title', 'link'])\n",
        "    for g in soup.find_all(class_='commit-title'):\n",
        "        entry = {}\n",
        "        title = g.find_all(class_='message')[0]['aria-label']\n",
        "        entry['title'] = title\n",
        "        links = g.find_all(class_='issue-link')\n",
        "        if len(links) >= 1:\n",
        "            link = links[0]['data-url']\n",
        "            entry['link'] = link\n",
        "        df = df.append(pd.DataFrame(entry, index=[0]), sort=False)\n",
        "    \n",
        "    df['repository'] = repo\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zjhbi8UXen7d"
      },
      "source": [
        "Let's try this out to get results for some ray related topics serially."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XENYO57kepSU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81620694-5df3-44dc-87fc-d2b373ea06bb"
      },
      "source": [
        "start = time.time()\n",
        "repos = [\"ray-project/ray\", \"modin-project/modin\", \"tensorflow/tensorflow\", \"apache/arrow\"]\n",
        "results = []\n",
        "for repo in repos:\n",
        "    df = fetch_commits.remote(repo)\n",
        "    results.append(df)\n",
        "    \n",
        "df = pd.concat(ray.get(results), sort=False)\n",
        "duration = time.time() - start\n",
        "print(\"Constructing the dataframe took {:.3f} seconds.\".format(duration))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Constructing the dataframe took 2.240 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eZ5VmqgoerPb"
      },
      "source": [
        "**EXERCISE**: Speed up the above serial query by making `fetch_commits` a remote function in order to scrape GitHub results in parallel. Then, see a sample of the data scraped below and feel free to play with the data to find other resources to learn more about these libraries!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "58RIGdF1etXY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d89a5c45-c049-416e-f002-6381069c7f4e"
      },
      "source": [
        "df"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>link</th>\n",
              "      <th>repository</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fix typo in examples/centralized_critic.py (#5...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5943</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Add dependencies for dashboard to installation...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5942</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Update max resource label and give better erro...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5916</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Autoscaler] Update AWS Deep Learning AMI to v...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5932</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Update TF documentation (#5918)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5918</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[tune] tf2.0 mnist example (#5898)\\n\\n* tfmnis...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5898</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Automatically create custom node id resource (...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5882</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[tune] Support TF2.0 on Keras Callback (#5912)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5912</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>remove evil redirects (#5919)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5919</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Deactivate bazel caching for linux wheels (#5915)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5915</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[tune] Explicitly set scheduler in run() (#587...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5871</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[docs] Pictures for all the Examples (#5859)\\n...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5859</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Add back TensorFlow test (#5885)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5885</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[autoscaler] Worker-Head termination + Better ...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5909</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bump dev version to 0.8.0.dev6 (#5906)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5906</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[tune] Remove TF MNIST example + add TrialRunn...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5868</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[tune] CPU-Only Head Node support (#5900)\\n\\n*...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5900</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fix test_dying_worker_get (#5908)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5908</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[autoscaler] uptime redirect fix (#5907)\\n\\n* ...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5907</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[autoscaler] Revert to double-spawning updater...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5903</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Serve] Remove handle passing in tail recursio...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5894</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rllib: use pytorch's fn to see if gpu is avail...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5890</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[minor][docs] Remove example link (#5880)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5880</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Don't wrap RayError with RayTaskError (#5870)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5870</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[autoscaler] Fix quoting (#5891)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5891</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Serve] Hotfix: Fix actor handle hashing in me...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5886</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Python 2 compatibility. (#5887)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5887</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fix str of RayTaskError (#5878)\\n\\n* fix key e...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5878</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fix linux wheel build (#5881)</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5881</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Dashboard] Improve handling of logs and error...</td>\n",
              "      <td>https://github.com/ray-project/ray/issues/5857</td>\n",
              "      <td>ray-project/ray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6898: [Java] Fix potential memory leak i...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6671: [C++][Python] Use more consistent ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6862: [Developer] Check pull request tit...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6901: [Rust] [Parquet] Increment total_n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6874: [Python] Fix memory leak when conv...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6903: [Python] Attempt to fix Python whe...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6876: [C++][Parquet] Use shared_ptr to a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6847: [C++] Add range_expression adapter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ARROW-6865][Java] Improve the performance of ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6814: [C++] Resolve compiler warnings oc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6853: [Java] Support vector and dictiona...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6659: [Rust] [DataFusion] Refactor of Ha...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6789: [Python] Improve ergonomics by aut...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6844: [C++][Parquet] Fix regression in r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6885: [Python] Remove superfluous skippe...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6567: [Rust] [DataFusion] Wrap aggregate...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6452: [Java] Override ValueVector toStri...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6184: [Java] Provide hash table based di...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6877: [C++] Add additional Boost version...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6882: [C++] Ensure the DictionaryArray i...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6283: [Rust] [DataFusion] Implement Cont...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-4219: [Rust] [Parquet] Initial support f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6857: [C++] Fix DictionaryEncode for zer...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6873: [Python] Remove stale CColumn refe...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6852: [C++] Fix build issue on memory-be...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6864: [C++] Add compression-related comp...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-4748: [Rust] [DataFusion] Optimize GROUP...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6860: [Python][C++] Do not link shared l...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-5680: [Rust] [DataFusion] GROUP BY sql t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARROW-6690: [Rust] [DataFusion] Optimize aggre...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>apache/arrow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  ...       repository\n",
              "0   Fix typo in examples/centralized_critic.py (#5...  ...  ray-project/ray\n",
              "0   Add dependencies for dashboard to installation...  ...  ray-project/ray\n",
              "0   Update max resource label and give better erro...  ...  ray-project/ray\n",
              "0   [Autoscaler] Update AWS Deep Learning AMI to v...  ...  ray-project/ray\n",
              "0                     Update TF documentation (#5918)  ...  ray-project/ray\n",
              "0   [tune] tf2.0 mnist example (#5898)\\n\\n* tfmnis...  ...  ray-project/ray\n",
              "0   Automatically create custom node id resource (...  ...  ray-project/ray\n",
              "0      [tune] Support TF2.0 on Keras Callback (#5912)  ...  ray-project/ray\n",
              "0                       remove evil redirects (#5919)  ...  ray-project/ray\n",
              "0   Deactivate bazel caching for linux wheels (#5915)  ...  ray-project/ray\n",
              "0   [tune] Explicitly set scheduler in run() (#587...  ...  ray-project/ray\n",
              "0   [docs] Pictures for all the Examples (#5859)\\n...  ...  ray-project/ray\n",
              "0                    Add back TensorFlow test (#5885)  ...  ray-project/ray\n",
              "0   [autoscaler] Worker-Head termination + Better ...  ...  ray-project/ray\n",
              "0              Bump dev version to 0.8.0.dev6 (#5906)  ...  ray-project/ray\n",
              "0   [tune] Remove TF MNIST example + add TrialRunn...  ...  ray-project/ray\n",
              "0   [tune] CPU-Only Head Node support (#5900)\\n\\n*...  ...  ray-project/ray\n",
              "0                   Fix test_dying_worker_get (#5908)  ...  ray-project/ray\n",
              "0   [autoscaler] uptime redirect fix (#5907)\\n\\n* ...  ...  ray-project/ray\n",
              "0   [autoscaler] Revert to double-spawning updater...  ...  ray-project/ray\n",
              "0   [Serve] Remove handle passing in tail recursio...  ...  ray-project/ray\n",
              "0   rllib: use pytorch's fn to see if gpu is avail...  ...  ray-project/ray\n",
              "0           [minor][docs] Remove example link (#5880)  ...  ray-project/ray\n",
              "0       Don't wrap RayError with RayTaskError (#5870)  ...  ray-project/ray\n",
              "0                    [autoscaler] Fix quoting (#5891)  ...  ray-project/ray\n",
              "0   [Serve] Hotfix: Fix actor handle hashing in me...  ...  ray-project/ray\n",
              "0                     Python 2 compatibility. (#5887)  ...  ray-project/ray\n",
              "0   Fix str of RayTaskError (#5878)\\n\\n* fix key e...  ...  ray-project/ray\n",
              "0                       Fix linux wheel build (#5881)  ...  ray-project/ray\n",
              "0   [Dashboard] Improve handling of logs and error...  ...  ray-project/ray\n",
              "..                                                ...  ...              ...\n",
              "0   ARROW-6898: [Java] Fix potential memory leak i...  ...     apache/arrow\n",
              "0   ARROW-6671: [C++][Python] Use more consistent ...  ...     apache/arrow\n",
              "0   ARROW-6862: [Developer] Check pull request tit...  ...     apache/arrow\n",
              "0   ARROW-6901: [Rust] [Parquet] Increment total_n...  ...     apache/arrow\n",
              "0   ARROW-6874: [Python] Fix memory leak when conv...  ...     apache/arrow\n",
              "0   ARROW-6903: [Python] Attempt to fix Python whe...  ...     apache/arrow\n",
              "0   ARROW-6876: [C++][Parquet] Use shared_ptr to a...  ...     apache/arrow\n",
              "0   ARROW-6847: [C++] Add range_expression adapter...  ...     apache/arrow\n",
              "0   [ARROW-6865][Java] Improve the performance of ...  ...     apache/arrow\n",
              "0   ARROW-6814: [C++] Resolve compiler warnings oc...  ...     apache/arrow\n",
              "0   ARROW-6853: [Java] Support vector and dictiona...  ...     apache/arrow\n",
              "0   ARROW-6659: [Rust] [DataFusion] Refactor of Ha...  ...     apache/arrow\n",
              "0   ARROW-6789: [Python] Improve ergonomics by aut...  ...     apache/arrow\n",
              "0   ARROW-6844: [C++][Parquet] Fix regression in r...  ...     apache/arrow\n",
              "0   ARROW-6885: [Python] Remove superfluous skippe...  ...     apache/arrow\n",
              "0   ARROW-6567: [Rust] [DataFusion] Wrap aggregate...  ...     apache/arrow\n",
              "0   ARROW-6452: [Java] Override ValueVector toStri...  ...     apache/arrow\n",
              "0   ARROW-6184: [Java] Provide hash table based di...  ...     apache/arrow\n",
              "0   ARROW-6877: [C++] Add additional Boost version...  ...     apache/arrow\n",
              "0   ARROW-6882: [C++] Ensure the DictionaryArray i...  ...     apache/arrow\n",
              "0   ARROW-6283: [Rust] [DataFusion] Implement Cont...  ...     apache/arrow\n",
              "0   ARROW-4219: [Rust] [Parquet] Initial support f...  ...     apache/arrow\n",
              "0   ARROW-6857: [C++] Fix DictionaryEncode for zer...  ...     apache/arrow\n",
              "0   ARROW-6873: [Python] Remove stale CColumn refe...  ...     apache/arrow\n",
              "0   ARROW-6852: [C++] Fix build issue on memory-be...  ...     apache/arrow\n",
              "0   ARROW-6864: [C++] Add compression-related comp...  ...     apache/arrow\n",
              "0   ARROW-4748: [Rust] [DataFusion] Optimize GROUP...  ...     apache/arrow\n",
              "0   ARROW-6860: [Python][C++] Do not link shared l...  ...     apache/arrow\n",
              "0   ARROW-5680: [Rust] [DataFusion] GROUP BY sql t...  ...     apache/arrow\n",
              "0   ARROW-6690: [Rust] [DataFusion] Optimize aggre...  ...     apache/arrow\n",
              "\n",
              "[140 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z-c-u7Nvewci"
      },
      "source": [
        "# Exercise 3 - Nested Parallelism\n",
        "\n",
        "**GOAL:** The goal of this exercise is to show how to create nested tasks by calling a remote function inside of another remote function.\n",
        "\n",
        "In this exercise, you will implement the structure of a parallel hyperparameter sweep which trains a number of models in parallel. Each model will be trained using parallel gradient computations.\n",
        "\n",
        "### Concepts for this Exercise - Nested Remote Functions\n",
        "\n",
        "Remote functions can call other functions. For example, consider the following.\n",
        "\n",
        "```python\n",
        "@ray.remote\n",
        "def f():\n",
        "    return 1\n",
        "\n",
        "@ray.remote\n",
        "def g():\n",
        "    # Call f 4 times and return the resulting object IDs.\n",
        "    results = []\n",
        "    for _ in range(4):\n",
        "      results.append(f.remote())\n",
        "    return results\n",
        "\n",
        "@ray.remote\n",
        "def h():\n",
        "    # Call f 4 times, block until those 4 tasks finish,\n",
        "    # retrieve the results, and return the values.\n",
        "    results = []\n",
        "    for _ in range(4):\n",
        "      results.append(f.remote())\n",
        "    return ray.get(results)\n",
        "```\n",
        "\n",
        "Then calling `g` and `h` produces the following behavior.\n",
        "\n",
        "```python\n",
        ">>> ray.get(g.remote())\n",
        "[ObjectID(b1457ba0911ae84989aae86f89409e953dd9a80e),\n",
        " ObjectID(7c14a1d13a56d8dc01e800761a66f09201104275),\n",
        " ObjectID(99763728ffc1a2c0766a2000ebabded52514e9a6),\n",
        " ObjectID(9c2f372e1933b04b2936bb6f58161285829b9914)]\n",
        "\n",
        ">>> ray.get(h.remote())\n",
        "[1, 1, 1, 1]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ppUDwvBMe0ue",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import ray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2aEuUdJDe-uY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eb2439c1-d872-43f8-b78a-8c8933df885f"
      },
      "source": [
        "ray.init(num_cpus=9, ignore_reinit_error=True)\n",
        "\n",
        "# Sleep a little to improve the accuracy of the timing measurements used below,\n",
        "# because some workers may still be starting up in the background.\n",
        "time.sleep(2.0)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-17 16:26:47,617\tERROR worker.py:1432 -- Calling ray.init() again after it has already been called.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RKX1DnmbfAJv"
      },
      "source": [
        "This example represents a hyperparameter sweep in which multiple models are trained in parallel. Each model training task also performs data parallel gradient computations.\n",
        "\n",
        "**EXERCISE:** Turn `compute_gradient` and `train_model` into remote functions so that they can be executed in parallel. Inside of `train_model`, do the calls to `compute_gradient` in parallel and fetch the results using `ray.get`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GAdMoSp7fBxV",
        "colab": {}
      },
      "source": [
        "@ray.remote\n",
        "def compute_gradient(data, current_model):\n",
        "    time.sleep(0.03)\n",
        "    return 1\n",
        "\n",
        "@ray.remote\n",
        "def train_model(hyperparameters):\n",
        "    current_model = 0\n",
        "    # Iteratively improve the current model. This outer loop cannot be parallelized.\n",
        "    for _ in range(10):\n",
        "        # EXERCISE: Parallelize the list comprehension in the line below. After you\n",
        "        # turn \"compute_gradient\" into a remote function, you will need to call it\n",
        "        # with \".remote\". The results must be retrieved with \"ray.get\" before \"sum\"\n",
        "        # is called.\n",
        "        total_gradient = sum(ray.get([compute_gradient.remote(j, current_model) for j in range(2)]))\n",
        "        current_model += total_gradient\n",
        "\n",
        "    return current_model\n",
        "\n",
        "assert hasattr(compute_gradient, 'remote'), 'compute_gradient must be a remote function'\n",
        "assert hasattr(train_model, 'remote'), 'train_model must be a remote function'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6yR2xgWhfEK3"
      },
      "source": [
        "**EXERCISE:** The code below runs 3 hyperparameter experiments. Change this to run the experiments in parallel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KQhgStdSfGMt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63ee87b5-71f9-4b2c-a949-0651f56472e4"
      },
      "source": [
        "# Sleep a little to improve the accuracy of the timing measurements below.\n",
        "time.sleep(2.0)\n",
        "start_time = time.time()\n",
        "\n",
        "# Run some hyperparaameter experiments.\n",
        "results1 = []\n",
        "for hyperparameters in [{'learning_rate': 1e-1, 'batch_size': 100},\n",
        "                        {'learning_rate': 1e-2, 'batch_size': 100},\n",
        "                        {'learning_rate': 1e-3, 'batch_size': 100}]:\n",
        "    results1.append(train_model.remote(hyperparameters))\n",
        "results = ray.get(results1)\n",
        "\n",
        "# EXERCISE: Once you've turned \"results\" into a list of Ray ObjectIDs\n",
        "# by calling train_model.remote, you will need to turn \"results\" back\n",
        "# into a list of integers, e.g., by doing \"results = ray.get(results)\".\n",
        "\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "print(\"Duration {}\".format(duration))\n",
        "assert all([isinstance(x, int) for x in results]), \\\n",
        "    'Looks like \"results\" is {}. You may have forgotten to call ray.get.'.format(results)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duration 0.4992406368255615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MZbRvJ9JfJcl"
      },
      "source": [
        "**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass.\n",
        "\n",
        "**NOTE:** This exercise is known to have issues running on remote notebooks that can be resolved by rerunning the above cell a second time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BN6QZZGEfLAu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35494fbd-bc8b-4f88-9100-630b3d0d9b40"
      },
      "source": [
        "assert results == [20, 20, 20]\n",
        "assert duration < 0.5, ('The experiments ran in {:.3f} seconds. This is too '\n",
        "                         'slow.'.format(duration))\n",
        "assert duration > 0.3, ('The experiments ran in {:.3f} seconds. This is too '\n",
        "                        'fast.'.format(duration))\n",
        "\n",
        "print('Success! The example took {:.3f} seconds.'.format(duration))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! The example took 0.499 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xuf2d5mrfMms"
      },
      "source": [
        "**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n",
        "\n",
        "1. Run the following cell to generate a JSON file containing the profiling data.\n",
        "2. Download the timeline file by right clicking on `exercise_3.json` in the **Files** tab in the navigator to the left, right clicking, and selecting  **\"Download\"**.\n",
        "3. Enter **chrome://tracing** into the Chrome web browser, click on the **\"Load\"** button, and select the downloaded JSON file.\n",
        "\n",
        "To navigate within the timeline:\n",
        "- Move around by clicking and dragging.\n",
        "- Zoom in and out by holding **alt** on Windows or **option** on Mac and scrolling.\n",
        "\n",
        "**NOTE:** The timeline visualization will only work in **Chrome**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WoR39fnfOlx",
        "colab": {}
      },
      "source": [
        "ray.timeline(filename=\"exercise_3.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozWMUKtBkTsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}